{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1388e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_height = 224  # Replace with your desired height\n",
    "img_width = 224   # Replace with your desired width\n",
    "\n",
    "# Load pre-trained VGG19 model without top classification layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features using VGG19\n",
    "def extract_features_vgg19(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = base_model.predict(x)\n",
    "    return features\n",
    "\n",
    "# Get features and labels for your dataset\n",
    "dataset_directory = 'D:/stft_images_output'  # Replace with your dataset path\n",
    "feature_list_vgg19 = []\n",
    "labels_vgg19 = []\n",
    "\n",
    "for directory in os.listdir(dataset_directory):\n",
    "    dir_path = os.path.join(dataset_directory, directory)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features_vgg19(img_path)\n",
    "            feature_list_vgg19.append(features)\n",
    "            labels_vgg19.append(directory)  # Assuming directory name is the class label\n",
    "\n",
    "# Concatenate features and convert labels to numeric format\n",
    "concatenated_features_vgg19 = np.concatenate(feature_list_vgg19, axis=0)\n",
    "label_dict_vgg19 = {label: index for index, label in enumerate(np.unique(labels_vgg19))}\n",
    "numeric_labels_vgg19 = [label_dict_vgg19[label] for label in labels_vgg19]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_vgg19 = concatenated_features_vgg19.reshape(concatenated_features_vgg19.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_vgg19 = pca.fit_transform(flatten_features_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c61ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_height = 224  # Replace with your desired height\n",
    "img_width = 224   # Replace with your desired width\n",
    "\n",
    "# Load pre-trained MobileNet model without top classification layers\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features using MobileNet\n",
    "def extract_features_mobilenet(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = base_model.predict(x)\n",
    "    return features\n",
    "\n",
    "# Get features and labels for your dataset\n",
    "dataset_directory = 'D:/stft_images_output'\n",
    "feature_list = []\n",
    "labels = []\n",
    "\n",
    "for directory in os.listdir(dataset_directory):\n",
    "    dir_path = os.path.join(dataset_directory, directory)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features_mobilenet(img_path)\n",
    "            feature_list.append(features)\n",
    "            labels.append(directory)  # Assuming directory name is the class label\n",
    "\n",
    "# Concatenate features and convert labels to numeric format\n",
    "concatenated_features = np.concatenate(feature_list, axis=0)\n",
    "label_dict = {label: index for index, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_mobilenet = concatenated_features.reshape(concatenated_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_mobilenet = pca.fit_transform(flatten_features_mobilenet)\n",
    "\n",
    "# Use reduced_features_mobilenet for further analysis or model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_features_shape = flatten_features_mobilenet.shape\n",
    "print(\"Size of flattened features after PCA:\", flattened_features_shape)\n",
    "np.save('numeric_labels_mobilenet.npy', numeric_labels)\n",
    "# Save the reduced features to a .npy file\n",
    "np.save('reduced_features_mobilenet.npy', reduced_features_mobilenet)\n",
    "np.save('labels_mobilenet.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_height = 299  # For InceptionV3, replace with desired height\n",
    "img_width = 299   # For InceptionV3, replace with desired width\n",
    "\n",
    "# Load pre-trained InceptionV3 model without top classification layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features using InceptionV3\n",
    "def extract_features_inceptionv3(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = base_model.predict(x)\n",
    "    return features\n",
    "\n",
    "# Get features and labels for your dataset\n",
    "dataset_directory = 'D:/stft_images_output'\n",
    "feature_list = []\n",
    "labels = []\n",
    "\n",
    "for directory in os.listdir(dataset_directory):\n",
    "    dir_path = os.path.join(dataset_directory, directory)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features_inceptionv3(img_path)\n",
    "            feature_list.append(features)\n",
    "            labels.append(directory)  # Assuming directory name is the class label\n",
    "\n",
    "# Concatenate features and convert labels to numeric format\n",
    "concatenated_features = np.concatenate(feature_list, axis=0)\n",
    "label_dict = {label: index for index, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_inceptionv3 = concatenated_features.reshape(concatenated_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_inceptionv3 = pca.fit_transform(flatten_features_inceptionv3)\n",
    "\n",
    "# Use reduced_features_inceptionv3 for further analysis or model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_features_shape = flatten_features_inceptionv3.shape\n",
    "print(\"Size of flattened features after PCA:\", flattened_features_shape)\n",
    "np.save('numeric_labels_inceptionv3.npy', numeric_labels)\n",
    "# Save the reduced features to a .npy file\n",
    "np.save('flatten_features_inceptionv3.npy', flatten_features_inceptionv3)\n",
    "np.save('labels_inceptionv3.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_height = 224  # Replace with your desired height\n",
    "img_width = 224   # Replace with your desired width\n",
    "\n",
    "# Load pre-trained ResNet50 model without top classification layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features using ResNet50\n",
    "def extract_features_resnet50(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = base_model.predict(x)\n",
    "    return features\n",
    "\n",
    "# Get features and labels for your dataset\n",
    "dataset_directory = 'D:/stft_images_output'\n",
    "feature_list = []\n",
    "labels = []\n",
    "\n",
    "for directory in os.listdir(dataset_directory):\n",
    "    dir_path = os.path.join(dataset_directory, directory)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features_resnet50(img_path)\n",
    "            feature_list.append(features)\n",
    "            labels.append(directory)  # Assuming directory name is the class label\n",
    "\n",
    "# Concatenate features and convert labels to numeric format\n",
    "concatenated_features = np.concatenate(feature_list, axis=0)\n",
    "label_dict = {label: index for index, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_resnet50 = concatenated_features.reshape(concatenated_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_resnet50 = pca.fit_transform(flatten_features_resnet50)\n",
    "\n",
    "# Use reduced_features_inceptionv3 for further analysis or model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_features = np.concatenate(feature_list, axis=0)\n",
    "label_dict = {label: index for index, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_resnet50 = concatenated_features.reshape(concatenated_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_resnet50 = pca.fit_transform(flatten_features_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('feature_list_resnet50.npy', feature_list)\n",
    "\n",
    "np.save('labels_resnet50.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea27642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_features_mobilenet, numeric_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define a simple fully connected neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(reduced_features_mobilenet.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))  # Output layer with number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with EarlyStopping callback\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Generate predictions for the test set\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Split the reduced features and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_features_mobilenet, numeric_labels, test_size=0.1, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Define an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define an LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1, X_train.shape[1])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(np.unique(numeric_labels)), activation='softmax'))  # Output layer with number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(X_test_lstm, y_test), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_lstm, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "predictions = model.predict(X_test_lstm)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70866ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are defined (before PCA dimensionality reduction)\n",
    "\n",
    "# Split the reduced features and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_features_mobilenet, numeric_labels, test_size=0.1, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Reshape the reduced features for GRU input (assuming a time-step of 1)\n",
    "X_train_gru = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_gru = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Define an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define a GRU model\n",
    "model = Sequential()\n",
    "model.add(GRU(128, input_shape=(1, X_train.shape[1])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(np.unique(numeric_labels)), activation='softmax'))  # Output layer with number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = model.fit(X_train_gru, y_train, epochs=50, batch_size=32,\n",
    "                    validation_data=(X_test_gru, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_gru, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "predictions = model.predict(X_test_gru)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_height = 224  # Replace with your desired height\n",
    "img_width = 224   # Replace with your desired width\n",
    "\n",
    "# Load pre-trained DenseNet121 model without top classification layers\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features using DenseNet\n",
    "def extract_features_densenet(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = base_model.predict(x)\n",
    "    return features\n",
    "\n",
    "# Get features and labels for your dataset\n",
    "dataset_directory = 'D:/stft_images_output'\n",
    "feature_list = []\n",
    "labels = []\n",
    "\n",
    "for directory in os.listdir(dataset_directory):\n",
    "    dir_path = os.path.join(dataset_directory, directory)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features_densenet(img_path)\n",
    "            feature_list.append(features)\n",
    "            labels.append(directory)  # Assuming directory name is the class label\n",
    "\n",
    "# Concatenate features and convert labels to numeric format\n",
    "concatenated_features = np.concatenate(feature_list, axis=0)\n",
    "label_dict = {label: index for index, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Flatten the extracted features\n",
    "flatten_features_densenet = concatenated_features.reshape(concatenated_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=200)  # Adjust the number of components as needed\n",
    "reduced_features_densenet = pca.fit_transform(flatten_features_densenet)\n",
    "\n",
    "# Use reduced_features_densenet for further analysis or model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_features_shape = flatten_features_densenet.shape\n",
    "print(\"Size of flattened features after PCA:\", flattened_features_shape)\n",
    "np.save('numeric_labels_densenet.npy', numeric_labels)\n",
    "# Save the reduced features to a .npy file\n",
    "np.save('reduced_features_densenet.npy', reduced_features_densenet)\n",
    "np.save('labels_densenet.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da40180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
